---
title: "Case Study 1"
author: "Marc Brooks, Bo Liu, Shirley Mathur, Aasha Reddy"
date: "10/6/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, 
                      fig.align = 'center')
```


To do (10/15):
- Data cleaning 
  -   get rid of states with 1 observation
- EDA
  -   Cooks distance by state for assumption checking
  -   For qq plot, don't try other transformations (square is too hard to interpret). Log transform takes the range to the whole real line 
- modeling 
  -   include interatctions using exhaustive search 
  -   include year as a factor 
  -   include empirical bayes (use BIC to select frequentist model then use frequentist results to inform priors, use uninformative variance priors)
  
  
  To do:
  - [Aasha] get rid of states with 1 obs
  - [Bo] change exhaustive search function 
  - [Marc] Cooks distance by state for assumption checking
  - [Bo] BRMS
  - [Shirley] interpret Bayesian 
  - [Shirley] Data cleaning report writing
  - [Aasha] EDA Report Writing
  - [Bo] Modeling Report Writing
  - [Marc] Interpretation Report Writing


```{r, warning=FALSE}
library(tidyverse)
library(lme4)
library(rstan)
library(brms)
library(knitr)
library(kableExtra)
library(patchwork)
library(lubridate)
library(gridExtra)

options(scipen = 0, digits = 4)
ggplot2::theme_set(ggplot2::theme_bw())
```


```{r}
#load data
# load("case_study_01/streetrx.RData")
load("~/Statistics - Duke University/2021 Fall/STA 610 - Hierarchical Models/STA_610_groupwork/case_study_01/streetrx.RData")

# GROUP 1 - METHADONE
# filter data for only methadone
streetrx <- streetrx %>%
  filter(api_temp == "methadone")
```

# Introduction

Prescription opioid diversion and abuse are major public health issues, and street prices provide an indicator of drug availability, demand, and abuse potential. Using StreetRx data, we aim to investigate factors related to the price per mg of Methadone. 

StreetRx (streetrx.com) is a web-based citizen reporting tool enabling real-time collection of street price data on diverted pharmaceutical substances. Based on principles of crowdsourcing for public health surveillance, the site allows users to anonymously report prices they paid or heard were paid for diverted prescription drugs. User-generated data offers intelligence into an otherwise opaque black market, providing a novel data set for public health surveillance, specifically for controlled substances.

Our goal is to investigate factors related to the price per mg of Methadone, accounting for potential clustering by location and exploring heterogeneity in pricing by location. Our data contains the following factors, and we will explore how the factors in the dataset are or are not associated with pricing per milligram. 

We first clean data and conduct exploratory data analysis (EDA) to assess any necessary transformations. We also conduct EDA to assess what type of model we should build, including which variables to include and to assess whether random intercepts or slopes would be helpful. We also use exhaustive search using BIC to perform variable selection. In our final model, we include random intercepts by state, and fixed effects for mgstr (), source (), and bulk_purchase (). We use estimates obtained from a frequentist version of the hierarchical model to inform priors for the final Bayesian version of the model. We find that _____. 

## Research Questions:
* Which variables are associated with pricing per milligram of Methadone? 
* Is there heterogeneity in pricing of Methadone by location? 

# Data and Cleaning

We first examine missing data in the streetrx data. We substitute NA for all missing values. We see that some variables, such as ppm, city, source, mgstr and primary_reason have many missing values. For the purpose of our model, we will not use the primary_reason variable, as they contain the most missing observations. Source contains links to websites where individuals purchased the Methadone, which will not be helpful in the model. 

We also note that individuals self-report their city, state, and country, so there are some data entry errors. For instance, some observations report purchased in "New York" vs. "New York Manhattan" vs. "New York City", which all refer to the same city. Thus, this variable may not be reliable as a grouping variable to explore heterogeneity within location. This is not an issue with State, so we choose to use state as our grouping variable. We also note that all purchases were made in the USA. 

```{r}
# variable description table
tibble(Variable = names(streetrx),
Description = c("Price per mg (outcome of interest)",
                "	Year and quarter drug was purchased",
                "Date of the reported purchase
",
                "city purchased",
                "state purchased",
"country purchased",
"northeast, midwest, west, south, or other/unknown
",
"source of information",
"active ingredient of drug of interest, in our case Methadone)
",
"formulation of the drug (e.g., pill, patch, suppository)
",
"dosage strength in mg of the units purchased
",
"indicator for purchase of 10+ units at once
",
"primary reason for purchase"
)) %>%
  kable(caption = "Variable Descriptions") %>%
  kable_styling(latex_options = "HOLD_position")
```

```{r}
# code missing data
streetrx <- data.frame(apply(streetrx, 2, function(x) gsub("^$|^ $", NA, x)))

# table of variables with missing data
# tibble(
#   Variable = names(streetrx), 
#   `Number Missing` = apply(streetrx, 2, function(x) sum(is.na(x))),
#   `Proportion Missing` = apply(streetrx, 2, function(x) mean(is.na(x)))
# ) %>%
#   kable(caption = "Number of observations missing per variable") %>%
#   kable_styling(latex_options = "HOLD_position")

# code factors and numeric variables 
streetrx <- streetrx %>%
  mutate(ppm = as.numeric(ppm), 
         yq_pdate = as.numeric(yq_pdate),
         price_date = mdy(price_date),
         city = as.factor(city), 
         state = as.factor(state),
         country = as.factor(country),
         USA_region = as.factor(USA_region),
         source = as.factor(source),
         form_temp = as.factor(form_temp),
         mgstr = as.numeric(mgstr),
         bulk_purchase = as.factor(bulk_purchase),
         Primary_Reason = as.factor(Primary_Reason)
         )

# add year
streetrx <- streetrx %>%
  mutate(year = year(price_date))

# delete observations with missing ppm data
streetrx <- streetrx %>%
  filter(!is.na(ppm))

# delete levels of mgstr that are not 5, 10, 40
streetrx <- streetrx %>%
  filter(mgstr %in% c(5,10,40)) %>%
  mutate(mgstr = as.factor(mgstr))

# delete year of 1969 as it is likely an error
streetrx <- streetrx %>%
  filter(year != 1969)

# delete state = USA
streetrx <- streetrx %>%
  filter(state != "USA")

#combine all website sources as being Internet source
streetrx <- streetrx %>%
  mutate(source = as.character(source)) %>%
  mutate(source = if_else(str_detect(source, "http://"), "Internet", source)) %>%
  mutate(source = if_else(str_detect(source, ".com$"), "Internet", source)) %>%
  mutate(source = if_else(source == "Streetrx", "Internet",source)) %>%
  mutate(source = if_else(source ==  "Poopy,", "N/A", source)) %>%
  mutate(source = if_else(source == "google", "Internet", source)) %>%
  mutate(source = if_else(source == "Internet Pharmacy", "Internet", source)) %>%
  mutate(source = na_if(source, "N/A")) %>%
  mutate(source = na_if(source, "None")) %>%
  mutate(source = as.factor(source))

# remove states with 1 observation
streetrx <- streetrx %>%
  group_by(state) %>%
  count() %>%
  filter(n > 1) %>%
  select(state) %>%
  left_join(streetrx, by = "state")
```

# EDA

### Checking distribution of outcome variable (ppm)

We explore the data first by examining the distribution of our outcome variable, price per mg (ppm). We next examine the distribution of our outcome variable, ppm (price per mg). We can see that ppm spans a large range of values, from \$0.00025/mg to \$40/mg. We note from the below histogram that the distribution is highly right-skewed. To satisfy the conditional distribution assumption, we want to aim for ppm to be normally distributed and symmetric. This of course only examines the marginal distribution of ppm, but the idea is that this may carry over into the conditional distribution, which we examine after the model fitting process

We choose to do a log transformation of ppm. We can see in the below plot that the histogram of log(ppm) is relatively normally distributed and symmetric. Using a log transformation is a good choice as well because our raw data ppm observation are all greater than 0, and log transformations are still interpretable, which is important in this case study. 

```{r, fig.height=2}
ppm_hist1 <- streetrx %>%
  ggplot(aes(x = ppm, y = ..density..)) +
  geom_histogram(alpha = 0.4, fill=rainbow(30), bins=30, color = "black") +
  geom_density(color = "black", adjust = 5)

ppm_hist2 <- streetrx %>%
  ggplot(aes(x = log(ppm), y = ..density..)) +
  geom_density(color = "black", adjust = 5) +
  geom_histogram(alpha = 0.4, fill=rainbow(20), bins=20, color = "black")

patchwork <- ppm_hist1 + ppm_hist2

patchwork + plot_annotation(
  title = "Distribution of ppm and log(ppm)")
```


### Assessing random intercepts 

There are a few options for grouping variables for a random intercept. We exclude `city` as we noted previously that this field is highly erroneous. We assess both `state` and `region` as potential grouping variables by examining heterogeneity of log(ppm) among both states and regions. From the below plots, we can see that there is not much variation of log(ppm) by region, but there is some variation by state. Thus, we will include a random intercept by state in our model. 

```{r, fig.height=4}
rand_int_state = ggplot(streetrx, aes(x = state, y = log(ppm))) + 
  geom_boxplot(aes(fill = factor(state)), outlier.size = 0.1) + 
  labs(x = "State") + 
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 7))

rand_int_region = ggplot(streetrx, aes(x = USA_region, y = log(ppm))) + 
  geom_boxplot(aes(fill = factor(USA_region)), outlier.size = 0.1) + 
  labs(x = "Region") + 
  theme(legend.position = "none", 
                axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

patchwork = rand_int_state + rand_int_region + plot_layout(widths = c(5, 1))

patchwork + plot_annotation(
  title = "Log(ppm) by state and region")
```


### Assessing relationship of variables with log(ppm)

We next assess relationships of variables in our dataset with log(ppm). This is useful to understand which variables may be most helpful to include as fixed effects in our model. We first examine year vs. log(ppm) and see that there is some evidence of a relationship. We also feel it is important to test for effects of year on log(ppm) to account for any potential inflation in the price of Methadone. Thus, we choose to include year as a fixed effect in our model selection process. We also note from the boxplot below that quarter does not seem to have variation by log(ppm), so we do not include this in our model. We wanted to consider this variable to account for any potential seasonality in the price of Methadone. 

```{r, fig.height=2}
ppm_year <- streetrx %>% 
  mutate(
    year = yq_pdate %/% 10, 
    quarter = yq_pdate %% 10
  ) %>%
  filter(year > 2009) %>%
  ggplot(., aes(x = year, y = log(ppm))) +
  geom_jitter(size = 0.2) + 
  labs(x = "Year") + 
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ppm_quarter <- streetrx %>% mutate(quarter = yq_pdate %% 10) %>%
  ggplot(aes(fill = factor(quarter))) + 
  geom_boxplot(aes(x = quarter, y = log(ppm), group = quarter), outlier.size = 0.1) + 
  theme(legend.position = "none") + 
  labs(x = "Quarter")

patchwork <- ppm_year + ppm_quarter + plot_layout(widths = c(2, 1))

patchwork + plot_annotation(
  title = "Log(ppm) by year and quarter"
)
```


We next assess the relationship of mgstr, bulk_purchase, and source by log(ppm) in the below boxplots. We see that all of these variables seem to have differences in log(ppm) by their respective levels, thus we choose to include mgstr, bulk_purchase, and source as fixed effects in our model selection process. 

```{r, fig.height=3.5}
mgstr_ppm <- ggplot(streetrx, aes(x = factor(mgstr), y = log(ppm))) + 
    geom_boxplot(aes(fill = factor(mgstr)), outlier.size = 0.1) + 
  labs(x = "mgstr") + 
  theme(legend.position = "none") +
  coord_flip()

bp_ppm <- ggplot(streetrx, aes(x = bulk_purchase, y = log(ppm))) + 
    geom_boxplot(aes(fill = bulk_purchase), outlier.size = 0.1) + 
  labs(x = "Bulk Purchase") + 
  theme(legend.position = "none") + 
  coord_flip()

source_ppm <- ggplot(streetrx, aes(x = source, y = log(ppm))) + 
    geom_boxplot(aes(fill = source), outlier.size = 0.1) + 
  labs(x = "Source") + 
  theme(legend.position = "none") +
  coord_flip()

patchwork <- mgstr_ppm / bp_ppm / source_ppm

patchwork + plot_annotation(
  title = "Log(ppm) vs. mgstr, bulk purchase, and source")
```

We note that form_temp (formulation of the drug as pill, patch, etc.) is always pill for Methadone, so we do not consider it as a potential variable in our model. The last variable in our dataset is primary reason for the purchase of Methadone. We note in the data cleaning section that this variable contains many missing observations, so we choose to exclude it. 


### Assessing Random Slopes

We next assess whether random slopes of our chosen variables by state would be useful. We note that we only have one continuous variable, year. In the below plots, we do not examine the trend of variables by all states. Instead, we filter for states with larger than 30 observations, and then choose a random sample of 8 states. 

We first examine the trend of the relationship of year with log(ppm) across 8 random states. We see that there is no distinguishable difference so we choose not to include a random slope of year by state. 

```{r, fig.height=3}
set.seed(7)
state_rand <- streetrx %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 30) %>%
  ungroup() %>%
  sample_n(8) %>%
  pull(state)

state_rand <- as.character(state_rand)

streetrx %>%
  filter(state %in% c(state_rand)) %>%
  ggplot(., aes(x = year, y = log(ppm))) + 
  geom_jitter(size = 0.2) + 
  facet_wrap(~state, ncol = 4) + 
  labs(title = "Distribution of log(ppm) by year and 8 random states") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


We then examine differences in the levels of mgstr, source, and bulk_purchase vs. log(ppm) by state. We created boxplots of each level of mgstr, source, and bulk_purchase vs. log(ppm) by state and did not find evidence of any major difference between the levels of the factors vs. log(ppm) by state. Thus we choose not to include any random slopes in our model. The boxplots can be found in the appendix. 


### Interactions 

Next we assess whether any interactions would be useful to include in our model. In our EDA, we examined plots of all 2-way interactions even though we do not include plots here. Outside of `mgstr` and `quarter`,  `bulk_purchase` and `quarter`, `source` and `mgstr`, and `bulk_purchase` and `mgstr` there was not strong evidence for other interaction effects. Even for those listed above the evidence was not substantial in our EDA, and some of the variation is likely due to a lack of observations for certain interaction terms. However, we test for inclusion of all 2-way interactions in our exhaustive search using BIC to make sure we capture any important interactions. 

### Overall choices and next steps 

Through EDA, we have made the decision to include a random intercept by state in our model selection process, as well as fixed effects for year, mgstr, bulk_purchase and source. We will proceed with using BIC using exhaustive search to choose the best combination of fixed effects and 2-way interactions.



```{r, include=FALSE, fig.show="hide"}
###### Extra Plots Fixed Effects ######################################

###### MGSTR ######
streetrx %>%
  ggplot(aes(x = mgstr)) +
  geom_bar(alpha = 0.4)

# Only three main levels of `mgstr`: 5mg, 10mg and 40mg.
streetrx %>% 
  filter(!is.na(mgstr)) %>%
  filter(!mgstr %in% c(5, 10, 40)) %>% 
  pull(mgstr)

ggplot(streetrx) +
  geom_point(aes(x = mgstr, y = log(ppm))) +
  geom_point(aes(x = mgstr, y = mean),
             data = streetrx %>% 
               group_by(mgstr) %>% 
               summarize(mean = mean(log(ppm))),
             color = "red"
)

# Seems that there is a slight association.
# cor(streetrx$ppm, streetrx$mgstr, use = "complete.obs")


###### DATES ######
streetrx %>% 
  mutate(
    year = yq_pdate %/% 10, 
    quarter = yq_pdate %% 10
  ) %>%
  group_by(year) %>% 
  summarize(n = n())

# 1969 seems to be erroneous
streetrx %>%
  filter(year(price_date) != yq_pdate %/% 10)

streetrx %>%
  filter((month(price_date) - 1) %/% 3 != yq_pdate %% 10 - 1)

# two dates are consistent

streetrx %>% filter(yq_pdate >= 20000) %>%
  mutate(year = yq_pdate %/% 10) %>%
  ggplot() + 
  geom_boxplot(aes(x = year, y = log(ppm), group = year))

streetrx %>% 
  filter(yq_pdate >= 20000) %>%
  mutate(days = difftime(price_date, '2000-01-01', units = "days")) %>%
  ggplot() +
  geom_point(aes(x = days, y = log(ppm)))

streetrx %>% 
  filter(yq_pdate >= 20090) %>%
  mutate(days = difftime(price_date, '2000-01-01', units = "days")) %>%
  ggplot() +
  geom_point(aes(x = days, y = log(ppm)))

###### GEOGRAPHICAL INFORMATION ######

ggplot(streetrx, aes(x = USA_region, y = log(ppm))) + 
  geom_boxplot(aes(fill = factor(USA_region))) + 
  labs(title = "Relationship between region and log(ppm)", 
       x = "Region") + 
  theme(legend.position = "none")

streetrx %>% group_by(USA_region) %>% summarize(n = n())

streetrx %>% 
  group_by(state) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))

###### form_temp ######
streetrx %>% group_by(form_temp) %>% summarize(n = n())
streetrx %>% group_by(form_temp, is.na(mgstr)) %>% summarize(n = n())
# All syrup/liquid rows do not have `mgstr` values. Basically we do not have any outcome data for syrup/liquid drugs

###### bulk_purchase ######
streetrx %>% group_by(bulk_purchase) %>% summarize(n = n())

```

```{r, include=FALSE, fig.show="hide"}
###### Extra Plots Interactions ######################################

###### 1.) `bulk_purchase` and `mgstr` ######

# The following boxplot does reveal some slight variance in the effect of `bulk_purchace` on `log(ppm)` across values of `mgstr`
ggplot(streetrx) + 
  geom_boxplot(aes(x = bulk_purchase, y = log(ppm))) +
  facet_wrap(~mgstr)

###### 2.) `source` and `mgstr` ######

# The following boxplot does reveal some slight variance in the effect of `source` on `log(ppm)` across different values of `mgstr`, though some of this effect could be distorted by lack of observations within certain categories.
ggplot(streetrx) + 
  geom_boxplot(aes(x = source, y = log(ppm))) +
  facet_wrap(~mgstr)

###### 3.) `source` and `bulk_purchase` ######

# The follow boxplot does not show substantial evidence that the relationship between log(ppm) and bulk_purchace varies across source.
ggplot(streetrx) + 
  geom_boxplot(aes(x = bulk_purchase, y = log(ppm))) +
  facet_wrap(~source)

###### 4.) `bulk_purchase` and `quarter` ######

# From the boxplot it appears that the relationship between quarter and log(ppm)changes slightly for different values of bulk_purchase.
streetrx %>%
  mutate(quarter = yq_pdate %% 10) %>%
  ggplot(aes(x = as.factor(quarter), y = log(ppm))) +
  geom_boxplot() +
  facet_wrap(~ bulk_purchase)

###### 5.) `mgstr` and `quarter` #####

# There is some evidence that the effect of quarter on log(ppm) changes with thedosage unit.
streetrx %>%
  mutate(quarter = yq_pdate %% 10) %>%
  ggplot(aes(x = as.factor(quarter), y = log(ppm))) +
  geom_boxplot() +
  facet_wrap(~ mgstr)

###### 6.) `source` and `quarter` ######

# We do not see strong evidence that the relationship between quarter and log(ppm) changes across source.
streetrx %>%
  mutate(quarter = yq_pdate %% 10) %>%
  ggplot(aes(x = as.factor(quarter), y = log(ppm))) +
  geom_boxplot() +
  facet_wrap(~ source)

###### 7.) Interactions between factor variables and year

###### 7.1) `mgstr` ######

# There is not strong evidence that `mgstr` effects the relationship between `year` and `log(ppm)`.

streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~mgstr) + 
  geom_smooth(method = "lm")  

streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  filter(year > 2005) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~mgstr) + 
  geom_smooth(method = "lm")  

###### 7.2) `bulk_purchase` ######
# There is not strong evidence that `bulk_purchase` effects the relationship between `year` and `log(ppm)`.
streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~bulk_purchase) + 
  geom_smooth(method = "lm")  


streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  filter(year > 2005) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~bulk_purchase) + 
  geom_smooth(method = "lm") 

###### 7.3) `source` ######

# There is not strong evidence that `source` effects the relationship between `year` and `log(ppm)`.
streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~source) + 
  geom_smooth(method = "lm")  

streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  filter(year > 2005) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~source) + 
  geom_smooth(method = "lm")  

# Outside of `mgstr` and `quarter`,  `bulk_purchase` and `quarter`, `source` and, and `mgstr` `bulk_purchase` and `mgstr` there was not strong evidence for other interaction effects. Even for those listed above the evidence was not substantial in our EDA, and some of the variation is likely due to a lack of observations for certain interaction terms.
```



# Model Building and Selection

**I do not have much information about what the best model should be, given that we are still in early EDA. Nevertheless, a priori I have some preference on what to use / what not to use.**

1) Grouping variable

- `USA_region` and `state` are natural grouping variables - and required for the analysis purpose.
- Grouping on binary variables is equivalent to a random slope for it. If we decide to put a random slope on a binary variable, we should put it as a grouping variable for ease to interpret.
- Other categorical variables are subject on how many levels we keep.

2) Base model

State: $s$. 

$$y_{is} = \mu + \alpha_{s} + \epsilon_{is}.$$

Where $y_{is}$ is the ppm for purchase $i$ in state $s$



See how much heterogeniety.

*May compare the fitted variance of regional level means and state level means. If regional level means have larger variance, it might indicate a clustering effect within regions.*

```{r}
model_plain <- 
  lmer(log(ppm) ~ 1 + (1 | state), data = streetrx, REML = F)
summary(model_plain)$AICtab
```

3) Adding predictors

Criterion: BIC(?) for Bayesian predictor selection.

We do an exhaustive search.

```{r}
exhaustive_search <- function(raw_model, vars, data, REML = F) {
  y_name <- deparse(raw_model[[2]])
  group_name <- deparse(raw_model[[3]])
  id <- 0 : (2^length(vars) - 1)
  construct_model <- function(.id){
    subset <- (.id %/% 2^(0:(length(vars) - 1))) %% 2 == 1
    if (all(subset == F)){
      RHS <- paste0(c("1", group_name), collapse = ' + ')
    }
    else {
      RHS <- paste0(c(vars[subset], group_name), collapse = ' + ')
    }
    paste(y_name, RHS, sep = ' ~ ')
  }
  run_model <- function(.id){
    model_str <- construct_model(.id)
    model_formula <- as.formula(model_str)
    res <- lmer(model_formula, REML = REML, data = data)
    return (summary(res)$AICtab)
  }
  
  bind_cols(
    model = sapply(id, construct_model),
    as.data.frame(t(sapply(id, run_model)))
  )
}
```


```{r}
ex_result <- exhaustive_search(
  raw_model <- log(ppm) ~ (1 | state),
  vars = c("year", "mgstr", "bulk_purchase", "source"),
  data = streetrx,
  REML = F
)
```

```{r, message = F}
ex_result_int <- exhaustive_search(
  raw_model <- log(ppm) ~ (1 | state),
  vars = c("year", "mgstr", "bulk_purchase", "source", 
           "year:mgstr", "year:bulk_purchase", "year:source",
           "mgstr:bulk_purchase", "mgstr:source", "bulk_purchase:source"),
  data = streetrx,
  REML = F
)
```

```{r}
ex_result %>% arrange(BIC) %>%
  select(1, 3) %>%
  kbl(caption = "Exhaustive search of fixed effects using BIC") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

```{r}
ex_result_int %>% arrange(BIC) %>% head(10) %>%
  select(1, 3) %>%
  kbl(caption = "Exhaustive search of fixed effects using BIC") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


Our best model is

$$
\begin{aligned}
y_{is} = \mu &+ \alpha_{s} + \beta_1I(mgstr_{is} = 10) + \beta_2I(mgstr_{is} = 40) + \beta_3I(bulkp_{is} = 1) \\
&+ \beta_4I(source_{is} = internet) + \beta_4I(source_{is} = personal) + \epsilon_{is}
\end{aligned}
$$

$$
\begin{aligned}
\alpha_s &\sim Normal(0, \tau^2) \\
\epsilon_{is} &\sim Normal(0, \sigma^2)
\end{aligned}
$$

Where $y_{is}$ is the ppm for purchase $i$ in state $s$

And $mgstr_{is}$, $bulkp_{is}$, and $source_{is}$ are fixed effects


```{r}
best_model <- ex_result %>% arrange(BIC) %>% .[1, "model"]
res <- lmer(as.formula(best_model), REML = F, data = streetrx)
summary(res)
```

```{r, message = F}
priors <- c(
  set_prior("normal(0, 1)", class = 'b'),
  set_prior("inv_gamma(0.1, 0.1)", class = "sd", group = "state"),
  set_prior("inv_gamma(0.1, 0.1)", class = 'sd')
)
bayes_result <- brm(as.formula(best_model), data = streetrx, prior = priors,
                    verbose = F, refresh = 0)
```
One can see that the results given by Bayesian setting is almost the same is that from the frequentist setting.

Posterior checks:

```{r}
plot(res)
```

Examine the normality of residuals

```{r}
residual <- resid(res)
p1 <- ggplot() + 
  geom_qq(aes(sample = residual)) +
  geom_qq_line(aes(sample = residual)) +
  coord_equal()
p2 <- ggplot() +
  geom_density(aes(x = residual))
p1 + p2
```

# Interpretation of results

Result plots:

### Fixed effects
```{r}
coef(summary(res)) %>%
  knitr::kable(caption = "Fixed effect estimates") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                latex_options = "HOLD_position")
```


As we took the log of our response ppm, we must exponentiate our estimates in order to interpret the effect of each variable on `ppm`. The following results are:

* Grand mean: Our estimated grand mean for `ppm` is 1.21. This is the average 
price per mg of methadone across all states for dosages of 50mg, cases where the purchase was heard of, 
and non bulk purchases.    

* `mgstr`: On average, we expect a decrease in dosage from 
50 mg to 10 mg to result in a 35.24% decrease in price and decrease from 50 mg 
to 40 mg to yield a 56.13% decrease in price.   

* `bulk_puchase`: On average bulk purchases are 12.41% cheaper, in terms of price per mg, 
than non bulk purchases.

* `source`: Purchases that were personally reported are on average 10% less
price per mg than purchases that had been heard second hand, while we expect a purchase that was discovered through the internet to be 33% less price per mg than a purchase that had been heard second hand.


### Random effects

The following illustrates the sorted estimated random state intercepts with 
95% confidence intervals.

```{r}
# dotplot
library(lattice)
dotplot(ranef(res, condVar = TRUE))$state
```

Overall the plot demonstrates significant heterogeneity across states in the baseline ppm of methadone for purchases that were in bulk and that had been reported by word of mouth. Three states, California, Missouri, and Arizona, do not contain 0 in their 95% confidence interval, implying a significant difference in their baseline ppm and the grand 
mean across all states. The plot also shows that the largest estimate was for Tennessee, 14.8% 
increase from the grand mean, while the smallest estimate was for California, a 18.13% decrease
from the grand mean. 


```{r}
as.data.frame(VarCorr(res)) %>%
  select(1, 4) %>%
  rename(var = vcov) %>%
  knitr::kable(caption = "Variance estimates") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                latex_options = "HOLD_position")
```

Our across state variance of ppm is fairly small at 0.0124 while the within state variance remains large at 0.6548. Clearly, there is still a lot of within-group variance that our model is unable to explain.

## Model Diagnostics (Influence of groups)   

#### Cook's Distance

Now that we have our final model we will perform, model diagnostics to determine if there are influential groups that might be effecting our model assumptions. First we will look at the DFBETAS of each parameter for each state. Following this, we use Cook's distance as another criteria to determine if there are cases of influential states.    

```{r}
library(influence.ME)
```

```{r}
best_model.inf <- influence(res, "state")
cutoff <- 2/sqrt(length(unique(streetrx$state)))
```


```{r}
dfbetas_inf <- round(dfbetas(best_model.inf), 4)
above_cutoff <- apply(abs(dfbetas_inf) > cutoff, MARGIN = 1, any)
dfbetas_inf[above_cutoff,] %>%
  knitr::kable(caption = "Level of influences states have on single parameter estiamtes") %>% 
  kable_styling(latex_options = "HOLD_position")

```


The above table contains the states such that at least one parameter had a standardized difference in their estimate that exceeded our cutoff when excluding that state. Note that many of the states included have the largest sample sizes in the data set.  

```{r, fig.height=15, fig.width=10}
plot(best_model.inf,which="dfbetas",xlab="DFBETAS",ylab="State")
```


```{r, fig.height=7, fig.width=5}
plot(best_model.inf,which="cook",cutoff=cutoff,
sort=TRUE,xlab="Cook's D",ylab="State")
```


When examining Cook's distance, Texas is the only state that exceeds the cutoff and can be considered influential. This is not surprising as Texas had multiple parameters such that their DFBETAS exceeded the cutoff and Cook's distance is a summary measure of how an observation influences all parameter estimates. While, it seems Texas is an influence group we have yet to determine if it is an outlier. At the same time, Texas is has the third largest sample size in the data set and is an important data point in the analysis so it does not make sense to consider deleting this group.

#### Normality



# Appendix

## Additional EDA

### Assessment of Random Slopes

```{r}
set.seed(7)
state_rand <- streetrx %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 30) %>%
  ungroup() %>%
  sample_n(8) %>%
  pull(state)

state_rand <- as.character(state_rand)

mgstr_rand_slope <- streetrx %>%
  filter(state %in% c(state_rand)) %>%
  ggplot(., aes(x = mgstr, y = log(ppm), fill = mgstr)) + 
  geom_boxplot() + 
  facet_wrap(~state, ncol = 4) + 
  theme(legend.position = "none") + 
  coord_flip()
```


```{r}
set.seed(0)
state_rand <- streetrx %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 30) %>%
  ungroup() %>%
  sample_n(8) %>%
  pull(state)

state_rand <- as.character(state_rand)

source_rand_slope <- streetrx %>%
  filter(state %in% c(state_rand)) %>%
  ggplot(., aes(x = source, y = log(ppm), fill = source)) + 
  geom_boxplot() + 
  facet_wrap(~state, ncol = 4) + 
  theme(legend.position = "none") + 
  coord_flip()
```


```{r}
set.seed(99)
state_rand <- streetrx %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 30) %>%
  ungroup() %>%
  sample_n(8) %>%
  pull(state)

state_rand <- as.character(state_rand)

bp_rand_slope <- streetrx %>%
  filter(state %in% c(state_rand)) %>%
  ggplot(., aes(x = bulk_purchase, y = log(ppm), fill = bulk_purchase)) + 
  geom_boxplot() + 
  facet_wrap(~state) + 
  theme(legend.position = "none") + 
  coord_flip()
```

```{r, fig.height=10}
patchwork <- mgstr_rand_slope / source_rand_slope / bp_rand_slope

patchwork + plot_annotation(
  title = "Log(ppm) vs. mgstr, bulk purchase, and source by 8 random states",
  subtitle = 'We do not observe difference in levels by state',
)
```

