---
title: "Case Study 1"
author: "Marc Brooks, Bo Liu, Shirley Mathur, Aasha Reddy"
date: "10/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```


To do:

Data cleaning (Shirley)
* Delete levels of mgstr that are not 5, 10, 40
* Delete year = 1969 
* Don't use missing data - ignore
* combine source into internet (categorical)


EDA (Marc)
* boxplot for source 
* check for interactions
* (wait until after presetnation) check for random slopes using EDA - choose 5 random states

Modeling (Bo)
* Don't use city 
* Group by state - log of ppm distribution is very similar across regions. Compare across region variances to within region variances - if it within is smaller means are more liekly to be the same. 
* use stepwise selection with BIC - start with base model and add covariates one by one. Exhaustive search (16)
* start with base model of only random intercepts (don't think about random slopes until after presetnation)
* primary_reason drop this variable - make a boxplot to see if log ppm distribution is different for price. From Mark's plot it doesn't look like they are different, so we can probably exclude this variable. Bo may explore this further - mention that if we had more time we could look into this more. 
* time - seasonality. Use quarter as a categorical variable. Maybe there is not a strong seasonal affect (looking at the boxplot). 
* use year as numerical variable (continuous) to account for potential inflation. 
* mgstr - include as a categorical 
* bulk purchase - we will include
* variables to include - log(ppm) ~ (1|state) + year + mgstr + bulk_purchase + source 
* check 2 models - check with 2004 and 2000 and then without these years and see how much it changes

Slides (Aasha)

To do (10/15):
- Data cleaning 
  -   get rid of states with 1 observation
- EDA
  -   Cooks distance by state for assumption checking
  -   For qq plot, don't try other transformations (square is too hard to interpret). Log transform takes the range to the whole real line 
- modeling 
  -   include interatctions using exhaustive search 
  -   include year as a factor 
  -   include empirical bayes (use BIC to select frequentist model then use frequentist results to inform priors, use uninformative variance priors)
  
  
  To do:
  - [Aasha] get rid of states with 1 obs
  - [Bo] change exhaustive search function 
  - [Marc] Cooks distance by state for assumption checking
  - [Bo] BRMS
  - [Shirley] interpret Bayesian 
  - [Shirley] Data cleaning report writing
  - [Aasha] EDA Report Writing
  - [Bo] Modeling Report Writing
  - [Marc] Interpretation Report Writing


```{r}
library(tidyverse)
library(lme4)
library(rstan)
library(brms)
library(knitr)
library(kableExtra)
library(patchwork)
library(lubridate)
library(gridExtra)

options(scipen = 0, digits = 4)
ggplot2::theme_set(ggplot2::theme_bw())
knitr::opts_chunk$set(
  fig.align = 'center', fig.width=5, fig.height=3, echo = FALSE
)
```


```{r}
#load data
load("streetrx.RData")

# GROUP 1 - METHADONE
# filter data for only methadone
streetrx <- streetrx %>%
  filter(api_temp == "methadone")
```

# Introduction, Data and Research Questions

Prescription opioid diversion and abuse are major public health issues, and street prices provide an indicator of drug availability, demand, and abuse potential. Using StreetRx data, we aim to investigate factors related to the price per mg of Methadone. 

StreetRx (streetrx.com) is a web-based citizen reporting tool enabling real-time collection of street price data on diverted pharmaceutical substances. Based on principles of crowdsourcing for public health surveillance, the site allows users to anonymously report prices they paid or heard were paid for diverted prescription drugs. User-generated data offers intelligence into an otherwise opaque black market, providing a novel data set for public health surveillance, specifically for controlled substances.

Our goal is to investigate factors related to the price per mg of Methadone, accounting for potential clustering by location and exploring heterogeneity in pricing by location. Our data contains the following factors, and we will explore how the factors in the dataset are or are not associated with pricing per milligram. 

We first clean data and conduct exploratory data analysis (EDA) to assess any necessary transformations. We also conduct EDA to assess what type of model we should build, including which variables to include and to assess whether random intercepts or slopes would be helpful. We also use exhaustive search using BIC to perform variable selection. In our final model, we include random intercepts by state, and fixed effects for mgstr (), source (), and bulk_purchase (). We use estimates obtained from a frequentist version of the hierarchical model to inform priors for the final Bayesian version of the model. We find that _____. 

## Research Questions:
* Which variables are associated with pricing per milligram of Methadone? 
* Is there heterogeneity in pricing of Methadone by location? 

```{r}
# variable description table
tibble(Variable = names(streetrx),
Description = c("Price per mg (outcome of interest)",
                "	Year and quarter drug was purchased",
                "Date of the reported purchase
",
                "city purchased",
                "state purchased",
"country purchased",
"northeast, midwest, west, south, or other/unknown
",
"source of information",
"active ingredient of drug of interest, in our case Methadone)
",
"formulation of the drug (e.g., pill, patch, suppository)
",
"dosage strength in mg of the units purchased
",
"indicator for purchase of 10+ units at once
",
"primary reason for purchase"
)) %>%
  kbl(caption = "Variable Descriptions", 
      position = "HOLD")
```

# Data Cleaning 

We first examine missing data in the streetrx data. We substitute NA for all missing values. We see that some variables, such as ppm, city, source, mgstr and primary_reason have many missing values. For the purpose of our model, we will not use the source or primary_reason variable, as they contain the most missing observations. Source contains links to websites where individuals purchased the Methadone, which will not be helpful in the model. 

We also note that individuals self-report their city, state, and country, so there are some data entry errors. For instance, some observations report purchased in "New York" vs. "New York Manhattan" vs. "New York City", which all refer to the same city. Thus, this variable may not be reliable as a grouping variable to explore heterogeneity within location. This is not an issue with State, so we choose to use state as our grouping variable. We also note that all purchases were made in the USA. 

---------------------
Added by Bo

1. Missing Values.

Five variables have missing values - `ppm`, `mgstr`, `city`, `source` and `Primary_Reason`.

Observations: 
- `Primary_Reason` has almost 50\% missing data.
- `source` and `city` has medium proportion of missing data.
- `ppm` and `mgstr` are missing at the same time.

What to do with these missing values?
- `Primary_Reason`: maybe can combine to several categories.
- `ppm` (12.65\%): outcome variable. Would hurt if the imputation is not reliable. **Suggestion: 1) discard missing observations - assume MCAR; 2) MI w/ sensitivity analysis; 3) test MI reliability first.**
- `source` (37.61\%): maybe try categorical - `Personal`, `Internet`, `Heard`, `Other`.
- `city` (33.24\%): basically can do nothing - delete.
- `mgstr` (12.65\%): depend on how you treat `ppm`. If missing data in `ppm` are discarded, then there are no missingness in `mgstr`.

```{r}
# code missing data
streetrx <- data.frame(apply(streetrx, 2, function(x) gsub("^$|^ $", NA, x)))

# table of variables with missing data
tibble(
  Variable = names(streetrx), 
  `Number Missing` = apply(streetrx, 2, function(x) sum(is.na(x))),
  `Proportion Missing` = apply(streetrx, 2, function(x) mean(is.na(x)))
) %>%
  kbl(caption = "Number of observations missing per variable",
    position = 'HOLD')

# code factors and numeric variables 
streetrx <- streetrx %>%
  mutate(ppm = as.numeric(ppm), 
         yq_pdate = as.numeric(yq_pdate),
         price_date = mdy(price_date),
         city = as.factor(city), 
         state = as.factor(state),
         country = as.factor(country),
         USA_region = as.factor(USA_region),
         source = as.factor(source),
         form_temp = as.factor(form_temp),
         mgstr = as.numeric(mgstr),
         bulk_purchase = as.factor(bulk_purchase),
         Primary_Reason = as.factor(Primary_Reason)
         )

# add year
streetrx <- streetrx %>%
  mutate(year = year(price_date))

# delete observations with missing ppm data
streetrx <- streetrx %>%
  filter(!is.na(ppm))

# delete levels of mgstr that are not 5, 10, 40
streetrx <- streetrx %>%
  filter(mgstr %in% c(5,10,40)) %>%
  mutate(mgstr = as.factor(mgstr))

# delete year of 1969 as it is likely an error
streetrx <- streetrx %>%
  filter(year != 1969)

# delete state = USA
streetrx <- streetrx %>%
  filter(state != "USA")

#combine all website sources as being Internet source
streetrx <- streetrx %>%
  mutate(source = as.character(source)) %>%
  mutate(source = if_else(str_detect(source, "http://"), "Internet", source)) %>%
  mutate(source = if_else(str_detect(source, ".com$"), "Internet", source)) %>%
  mutate(source = if_else(source == "Streetrx", "Internet",source)) %>%
  mutate(source = if_else(source ==  "Poopy,", "N/A", source)) %>%
  mutate(source = if_else(source == "google", "Internet", source)) %>%
  mutate(source = if_else(source == "Internet Pharmacy", "Internet", source)) %>%
  mutate(source = na_if(source, "N/A")) %>%
  mutate(source = na_if(source, "None")) %>%
  mutate(source = as.factor(source))

# remove states with 1 observation
streetrx <- streetrx %>%
  group_by(state) %>%
  count() %>%
  filter(n > 1) %>%
  select(state) %>%
  left_join(streetrx, by = "state")
```

# EDA

### Checking distribution of outcome variable (ppm)

We explore the data first by examining the distribution of our outcome variable, price per mg (ppm). We next examine the distribution of our outcome variable, ppm (price per mg). We can see that ppm spans a large range of values, from \$0.00025/mg to \$40/mg. We note from the below histogram that the distribution is highly right-skewed. To satisfy the conditional distribution assumption, we want to aim for ppm to be normally distributed and symmetric. This of course only examines the marginal distribution of ppm, but the idea is that this may carry over into the conditional distribution, which we examine after the model fitting process

We choose to do a log transformation of ppm. We can see in the below plot that the histogram of log(ppm) is relatively normally distributed and symmetric. Using a log transformation is a good choice as well because our raw data ppm observation are all greater than 0, and log transformations are still interpretable, which is important in this case study. 

```{r}
ppm_hist1 <- streetrx %>%
  ggplot(aes(x = ppm, y = ..density..)) +
  geom_histogram(alpha = 0.4, fill=rainbow(30), bins=30, color = "black") +
  geom_density(color = "black", adjust = 5)

ppm_hist2 <- streetrx %>%
  ggplot(aes(x = log(ppm), y = ..density..)) +
  geom_density(color = "black", adjust = 5) +
  geom_histogram(alpha = 0.4, fill=rainbow(20), bins=20, color = "black")

patchwork <- ppm_hist1 + ppm_hist2

patchwork + plot_annotation(
  title = "Distribution of ppm and log(ppm)",
  subtitle = 'Log(ppm) is more normally distributed and symmetric',
)
```

```{r, include=FALSE}
ggplot(data = streetrx, aes(x = ppm)) + 
  geom_histogram(color = "white", bins = 50) + 
  labs(y = "", 
       title = "Distribution of price per mg (ppm) \nof Methadone")
```

```{r, include=FALSE}
streetrx %>%
  filter(ppm < 10) %>%
ggplot(data = ., aes(x = ppm)) + 
  geom_histogram(color = "white", bins = 50) + 
  labs(y = "", 
       title = "Distribution of price per mg (ppm) < 10 \nof Methadone")
```


### Assessing random intercepts 

There are a few options for grouping variables for a random intercept. We exclude `city` as we noted previously that this field is highly erroneous. We assess both `state` and `region` as potential grouping variables by examining heterogeneity of log(ppm) among both states and regions. From the below plots, we can see that there is not much variation of log(ppm) by region, but there is some variation by state. Thus, we will include a random intercept by state in our model. 

```{r}
rand_int_state = ggplot(streetrx, aes(x = state, y = log(ppm))) + 
  geom_boxplot(aes(fill = factor(state))) + 
  labs(x = "State") + 
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 7))

rand_int_region = ggplot(streetrx, aes(x = USA_region, y = log(ppm))) + 
  geom_boxplot(aes(fill = factor(USA_region))) + 
  labs(x = "Region") + 
  theme(legend.position = "none", 
                axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

patchwork = rand_int_state + rand_int_region + plot_layout(widths = c(5, 1))

patchwork + plot_annotation(
  title = "Log(ppm) by state and region",
  subtitle = 'We observe some heterogeneity of log(ppm) by state',
)
```


### Assessing relationship of variables with log(ppm)

We next assess relationships of variables in our dataset with log(ppm). This is useful to understand which variables may be most helpful to include as fixed effects in our model. We first examine year vs. log(ppm) and see that there is some evidence of a relationship. We also feel it is important to test for effects of year on log(ppm) to account for any potential inflation in the price of Methadone. Thus, we choose to include year as a fixed effect in our model selection process. 

```{r}
streetrx %>% 
  mutate(
    year = yq_pdate %/% 10, 
    quarter = yq_pdate %% 10
  ) %>%
  filter(year > 2009) %>%
  ggplot(., aes(x = year, y = log(ppm))) +
  geom_jitter() + 
  labs(title = "Relationship between year and log(ppm)", 
       x = "Year") + 
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

We next assess the relationship of mgstr, bulk_purchase, and source by log(ppm) in the below boxplots. We see that all of these variables seem to have differences in log(ppm) by their respective levels, thus we choose to include mgstr, bulk_purchase, and source as fixed effects in our model selection process. 

4) `bulk_purchase`

```{r}
ggplot(streetrx, aes(x = bulk_purchase, y = log(ppm))) + 
    geom_boxplot(aes(fill = bulk_purchase)) + 
  labs(title = "Relationship between bulk_purchase and log(ppm)", 
       x = "Bulk Purchase") + 
  theme(legend.position = "none")
```

5) `source` and `Primary_Reason`

```{r}
ggplot(streetrx, aes(x = source, y = log(ppm))) + 
    geom_boxplot(aes(fill = source)) + 
  labs(title = "Relationship between source and log(ppm)", 
       x = "Source") + 
  theme(legend.position = "none")
```


We note that form_temp (formulation of the drug as pill, patch, etc.) is always pill for Methadone, so we do not consider it as a potential variable in our model. We also note from the boxplot below that quarter does not seem to have variation by log(ppm), so we do not include this in our model. We wanted to consider this variable to account for any potential seasonality in the price of Methadone. 

[insert quarter boxplot]

The last variable in our dataset is primary reason for the purchase of Methadone. We note that there is not much evidence of heterogeneity of log(ppm) for the different primary reasons, so we do not include this as a potential variable in our model.

[insert boxplot of primary reason]


#### Determine that random slopes are not useful to consider in our model

We next assess whether random slopes of our chosen variables by state would be useful. We note that we only have one continuous variable, year. In the below plots, we do not examine the trend of variables by all states. Instead, we filter for states with larger than 30 observations, and then choose a random sample of 8 states. 

We first examine the trend of the relationship of year with log(ppm) across 8 random states. We see that there is no distinguishable difference so we choose not to include a random slope of year by state. 

[insert plot of year vs. log(ppm) by state]

We then examine differences in the levels of mgstr, source, and bulk_purchase vs. log(ppm) by state. We see from the below boxplots that there is not evidence of any major difference between the levels of the factors vs. log(ppm) by state. Thus we choose not to include any random slopes in our model.

#### Interactions 

Next we assess whether any interactions would be useful to include in our model. In our EDA, we examined plots of all 2-way interactions and did not see much evidence for the necessity of interactions. However, we test for inclusion of all 2-way interactions in our exhaustive search using BIC to make sure we capture any important interactions. 

#### Overall choices and next steps 

Through EDA, we have made the decision to include a random intercept by state in our model selection process, as well as fixed effects for year, mgstr, bulk_purchase and source. We will proceed with using BIC using exhaustive search to choose the best combination of fixed effects and 2-way interactions. 





2. Distribution of Variables

1) outcome: `ppm`



2) `mgstr`

```{r}
mgstr_hist1 <- streetrx %>%
  ggplot(aes(x = mgstr)) +
  geom_bar(alpha = 0.4)
  
mgstr_hist1
```

Only three main levels of `mgstr`: 5mg, 10mg and 40mg.

```{r}
streetrx %>% 
  filter(!is.na(mgstr)) %>%
  filter(!mgstr %in% c(5, 10, 40)) %>% 
  pull(mgstr)
```

```{r}
ggplot(streetrx, aes(x = factor(mgstr), y = log(ppm))) + 
    geom_boxplot(aes(fill = factor(mgstr))) + 
  labs(title = "Relationship between mgstr and log(ppm)", 
       x = "mgstr") + 
  theme(legend.position = "none")
```


3) Dates



```{r}
streetrx %>% 
  mutate(
    year = yq_pdate %/% 10, 
    quarter = yq_pdate %% 10
  ) %>%
  group_by(year) %>% 
  summarize(n = n())
```

1969 seems to be erroneous.

```{r}
streetrx %>%
  filter(year(price_date) != yq_pdate %/% 10)
```

```{r}
streetrx %>%
  filter((month(price_date) - 1) %/% 3 != yq_pdate %% 10 - 1)
```


Two dates are consistent.

4) Geographical information


```{r}
ggplot(streetrx, aes(x = USA_region, y = log(ppm))) + 
  geom_boxplot(aes(fill = factor(USA_region))) + 
  labs(title = "Relationship between region and log(ppm)", 
       x = "Region") + 
  theme(legend.position = "none")
```

```{r}
streetrx %>% group_by(USA_region) %>% summarize(n = n())
```

```{r}
streetrx %>% 
  group_by(state) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))
```

Some states have very few observations - might be more stable to use a hierarchical model. **Think of whether to use regional information (another level of hierarchy)**

5) `form_temp`

```{r}
streetrx %>% group_by(form_temp) %>% summarize(n = n())
```

```{r}
streetrx %>% group_by(form_temp, is.na(mgstr)) %>% summarize(n = n())
```

**All syrup/liquid rows do not have `mgstr` values. Basically we do not have any outcome data for syrup/liquid drugs.**

6) `bulk_purchase`

```{r}
streetrx %>% group_by(bulk_purchase) %>% summarize(n = n())
```

3. Association with outcome `ppm`

1) `mgstr`

```{r}
ggplot(streetrx) +
  geom_point(aes(x = mgstr, y = log(ppm))) +
  geom_point(aes(x = mgstr, y = mean),
             data = streetrx %>% 
               group_by(mgstr) %>% 
               summarize(mean = mean(log(ppm))),
             color = "red"
)
```

Seems that there is a slight association.

```{r}
cor(streetrx$ppm, streetrx$mgstr, use = "complete.obs")
```

2) Dates

```{r}
streetrx %>% mutate(quarter = yq_pdate %% 10) %>%
  ggplot() + 
  geom_boxplot(aes(x = quarter, y = log(ppm), group = quarter))
```

```{r}
streetrx %>% filter(yq_pdate >= 20000) %>%
  mutate(year = yq_pdate %/% 10) %>%
  ggplot() + 
  geom_boxplot(aes(x = year, y = log(ppm), group = year))
```

```{r}
streetrx %>% 
  filter(yq_pdate >= 20000) %>%
  mutate(days = difftime(price_date, '2000-01-01', units = "days")) %>%
  ggplot() +
  geom_point(aes(x = days, y = log(ppm)))
```

```{r}
streetrx %>% 
  filter(yq_pdate >= 20090) %>%
  mutate(days = difftime(price_date, '2000-01-01', units = "days")) %>%
  ggplot() +
  geom_point(aes(x = days, y = log(ppm)))
```

3) Geographical information

```{r}
ggplot(streetrx) +
  geom_boxplot(aes(x = USA_region, y = log(ppm)))
```

```{r}
ggplot(streetrx) +
  geom_boxplot(aes(x = state, y = log(ppm)))
```



**Depend on how we discuss to deal with these variables.**

4. Detecting Interaction Effects

1.) `bulk_purchase` and `mgstr`

The following boxplot does reveal some slight variance in the effect of `bulk_purchace` 
on `log(ppm)` across values of `mgstr`.

```{r}
ggplot(streetrx) + 
  geom_boxplot(aes(x = bulk_purchase, y = log(ppm))) +
  facet_wrap(~mgstr)
```
2.) `source` and `mgstr`

The following boxplot does reveal some slight variance in the effect of `source` 
on `log(ppm)` across different values of `mgstr`, though some of this effect 
could be distorted by lack of observations within certain categories.

```{r}
ggplot(streetrx) + 
  geom_boxplot(aes(x = source, y = log(ppm))) +
  facet_wrap(~mgstr)
```
3.) `source` and `bulk_purchase`

The follow boxplot does not show substantial evidence that the relationship
between log(ppm) and bulk_purchace varies across source.

```{r}
ggplot(streetrx) + 
  geom_boxplot(aes(x = bulk_purchase, y = log(ppm))) +
  facet_wrap(~source)
```

4.) `bulk_purchase` and `quarter`

From the boxplot it appears that the relationship between quarter and log(ppm) 
changes slightly for different values of bulk_purchase.

```{r}
streetrx %>%
  mutate(quarter = yq_pdate %% 10) %>%
  ggplot(aes(x = as.factor(quarter), y = log(ppm))) +
  geom_boxplot() +
  facet_wrap(~ bulk_purchase)
```

5.) `mgstr` and `quarter`

There is some evidence that the effect of quarter on log(ppm) changes with the 
dosage unit.

```{r}
streetrx %>%
  mutate(quarter = yq_pdate %% 10) %>%
  ggplot(aes(x = as.factor(quarter), y = log(ppm))) +
  geom_boxplot() +
  facet_wrap(~ mgstr)
```

6.) `source` and `quarter`

We do not see strong evidence that the relationship between quarter and log(ppm) 
changes across source.

```{r}
streetrx %>%
  mutate(quarter = yq_pdate %% 10) %>%
  ggplot(aes(x = as.factor(quarter), y = log(ppm))) +
  geom_boxplot() +
  facet_wrap(~ source)
```

7.) Interactions between factor variables and year

7.1) `mgstr`

There is not strong evidence that `mgstr` effects the relationship between `year`
and `log(ppm)`.

```{r}
streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~mgstr) + 
  geom_smooth(method = "lm")  
```

```{r}
streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  filter(year > 2005) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~mgstr) + 
  geom_smooth(method = "lm")  
```
7.2) `bulk_purchase`
There is not strong evidence that `bulk_purchase` effects the relationship between `year`
and `log(ppm)`.
```{r}
streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~bulk_purchase) + 
  geom_smooth(method = "lm")  
```


```{r}
streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  filter(year > 2005) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~bulk_purchase) + 
  geom_smooth(method = "lm")  
```
7.3) `source`
There is not strong evidence that `source` effects the relationship between `year`
and `log(ppm)`.
```{r}
streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~source) + 
  geom_smooth(method = "lm")  
```


```{r}
streetrx %>% 
  mutate(year = yq_pdate %/% 10) %>% 
  filter(year > 2005) %>% 
  ggplot(aes(x=year, y = log(ppm)))  +
  geom_point() +
  facet_wrap(~source) + 
  geom_smooth(method = "lm")  
```

Outside of `mgstr` and `quarter`,  `bulk_purchase` and `quarter`, `source` and,
and `mgstr` `bulk_purchase` and `mgstr` there was not strong evidence for other 
interaction effects. Even for those listed above the evidence was not substantial 
in our EDA, and some of the variation is likely due to a lack of observations
for certain interaction terms.

## EDA for Random slopes

1) Mgstr and state

```{r}
set.seed(7)
state_rand <- streetrx %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 30) %>%
  ungroup() %>%
  sample_n(8) %>%
  pull(state)

state_rand <- as.character(state_rand)

streetrx %>%
  filter(state %in% c(state_rand)) %>%
  ggplot(., aes(x = mgstr, y = log(ppm))) + 
  geom_boxplot() + 
  facet_wrap(~state) + 
  labs(title = "Distribution of log(ppm) by mgstr and 8 random states")
```

2) source and state

```{r}
set.seed(0)
state_rand <- streetrx %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 30) %>%
  ungroup() %>%
  sample_n(8) %>%
  pull(state)

state_rand <- as.character(state_rand)

streetrx %>%
  filter(state %in% c(state_rand)) %>%
  ggplot(., aes(x = source, y = log(ppm))) + 
  geom_boxplot() + 
  facet_wrap(~state) + 
  labs(title = "Distribution of log(ppm) by source and 8 random states")
```

3) year and state

```{r}
set.seed(7)
state_rand <- streetrx %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 30) %>%
  ungroup() %>%
  sample_n(8) %>%
  pull(state)

state_rand <- as.character(state_rand)

streetrx %>%
  filter(state %in% c(state_rand)) %>%
  ggplot(., aes(x = year, y = log(ppm))) + 
  geom_point() + 
  facet_wrap(~state) + 
  labs(title = "Distribution of log(ppm) by year and 8 random states")
```

4) bulk_purchase and state

```{r}
set.seed(99)
state_rand <- streetrx %>%
  group_by(state) %>%
  count() %>%
  arrange(desc(n)) %>%
  filter(n > 30) %>%
  ungroup() %>%
  sample_n(8) %>%
  pull(state)

state_rand <- as.character(state_rand)

streetrx %>%
  filter(state %in% c(state_rand)) %>%
  ggplot(., aes(x = bulk_purchase, y = log(ppm))) + 
  geom_boxplot() + 
  facet_wrap(~state) + 
  labs(title = "Distribution of log(ppm) by bulk_purchase \nand 8 random states") + 
  coord_flip()
```


5. Model

**I do not have much information about what the best model should be, given that we are still in early EDA. Nevertheless, a priori I have some preference on what to use / what not to use.**

1) Grouping variable

- `USA_region` and `state` are natural grouping variables - and required for the analysis purpose.
- Grouping on binary variables is equivalent to a random slope for it. If we decide to put a random slope on a binary variable, we should put it as a grouping variable for ease to interpret.
- Other categorical variables are subject on how many levels we keep.

2) Base model

State: $s$. 

$$y_{is} = \mu + \alpha_{s} + \epsilon_{is}.$$

Where $y_{is}$ is the ppm for purchase $i$ in state $s$



See how much heterogeniety.

*May compare the fitted variance of regional level means and state level means. If regional level means have larger variance, it might indicate a clustering effect within regions.*

```{r}
model_plain <- 
  lmer(log(ppm) ~ 1 + (1 | state), data = streetrx, REML = F)
summary(model_plain)$AICtab
```

3) Adding predictors

Criterion: BIC(?) for Bayesian predictor selection.

We do an exhaustive search.

```{r}
exhaustive_search <- function(raw_model, vars, data, REML = F) {
  y_name <- deparse(raw_model[[2]])
  group_name <- deparse(raw_model[[3]])
  id <- 0 : (2^length(vars) - 1)
  construct_model <- function(.id){
    subset <- (.id %/% 2^(0:(length(vars) - 1))) %% 2 == 1
    if (all(subset == F)){
      RHS <- paste0(c("1", group_name), collapse = ' + ')
    }
    else {
      RHS <- paste0(c(vars[subset], group_name), collapse = ' + ')
    }
    paste(y_name, RHS, sep = ' ~ ')
  }
  run_model <- function(.id){
    model_str <- construct_model(.id)
    model_formula <- as.formula(model_str)
    res <- lmer(model_formula, REML = REML, data = data)
    return (summary(res)$AICtab)
  }
  
  bind_cols(
    model = sapply(id, construct_model),
    as.data.frame(t(sapply(id, run_model)))
  )
}
```

```{r}

```


```{r}
ex_result <- exhaustive_search(
  raw_model <- log(ppm) ~ (1 | state),
  vars = c("year", "mgstr", "bulk_purchase", "source"),
  data = streetrx,
  REML = F
)
```

```{r, message = F}
ex_result_int <- exhaustive_search(
  raw_model <- log(ppm) ~ (1 | state),
  vars = c("year", "mgstr", "bulk_purchase", "source", 
           "year:mgstr", "year:bulk_purchase", "year:source",
           "mgstr:bulk_purchase", "mgstr:source", "bulk_purchase:source"),
  data = streetrx,
  REML = F
)
```

```{r}
ex_result %>% arrange(BIC) %>%
  select(1, 3) %>%
  kbl(caption = "Exhaustive search of fixed effects using BIC") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

```{r}
ex_result_int %>% arrange(BIC) %>% head(10) %>%
  select(1, 3) %>%
  kbl(caption = "Exhaustive search of fixed effects using BIC") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


Our best model is

$$
y_{is} = \mu + \alpha_{s} + \beta_1I(mgstr_{is} = 10) + \beta_2I(mgstr_{is} = 40) + \beta_3I(bulkp_{is} = 1) + \beta_4I(source_{is} = internet) + \beta_4I(source_{is} = personal) + \epsilon_{is}
$$

$\alpha_s \sim Normal(\0, \tau^2)$

$\epsilon_{is} \sim Normal(0, \sigma^2)$ 

Where $y_{is}$ is the ppm for purchase $i$ in state $s$

And $mgstr_{is}$, $bulkp_{is}$, and $source_{is}$ are fixed effects


```{r}
best_model <- ex_result %>% arrange(BIC) %>% .[1, "model"]
res <- lmer(as.formula(best_model), REML = F, data = streetrx)
summary(res)
```

```{r, message = F}
priors <- c(
  set_prior("normal(0, 1)", class = 'b'),
  set_prior("inv_gamma(0.1, 0.1)", class = "sd", group = "state"),
  set_prior("inv_gamma(0.1, 0.1)", class = 'sd')
)
bayes_result <- brm(as.formula(best_model), data = streetrx, prior = priors,
                    verbose = F, refresh = 0)
```
One can see that the results given by Bayesian setting is almost the same is that from the frequentist setting.

Posterior checks:

```{r}
plot(res)
```

Examine the normality of residuals

```{r}
residual <- resid(res)
p1 <- ggplot() + 
  geom_qq(aes(sample = residual)) +
  geom_qq_line(aes(sample = residual)) +
  coord_equal()
p2 <- ggplot() +
  geom_density(aes(x = residual))
p1 + p2
```

Result plots:

```{r}
# dotplot
library(lattice)
dotplot(ranef(res, condVar = TRUE))$state
```

```{r}
coef(summary(res)) %>%
  kbl(caption = "Fixed effect estimates") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

```{r}
as.data.frame(VarCorr(res)) %>%
  select(1, 4) %>%
  rename(var = vcov) %>%
  kbl(caption = "Variance estimates") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


